{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workbook, I will try to implement the Adaboost algorithm, based on the decision tree stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data set. In this example, I will use the Iris dataset from skleanr\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features' names are:  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "The target names are: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "## check other properties\n",
    "\n",
    "print (\"The features' names are: \", iris.feature_names)\n",
    "print (\"The target names are:\", iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert the data to dataframe\n",
    "\n",
    "iris_df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df['target'] = Y\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    5.9\n",
       "sepal width (cm)     3.0\n",
       "petal length (cm)    5.1\n",
       "petal width (cm)     1.8\n",
       "target               2.0\n",
       "Name: 149, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.iloc[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df['target'] = iris_df['target'].apply(lambda x: 1 if x==2 else 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df0 = iris_df.iloc[0:150, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100\n",
       "1     50\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Here we use iris_df0 as the training dataset\n",
    "\n",
    "iris_df0['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Decision tree stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = iris_df0.iloc[:, 0:4]\n",
    "Y0 = iris_df0.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print (X0.shape)\n",
    "print (Y0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test splitting\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X0, Y0, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4)\n",
      "(105,)\n"
     ]
    }
   ],
   "source": [
    "## check the size of the X_train and X_test\n",
    "\n",
    "print (X_train.shape)\n",
    "assert (X_train.shape[0] == Y_train.shape[0])\n",
    "print (Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "tree.fit(X_train, Y_train)\n",
    "\n",
    "## prediction\n",
    "y_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.911111111111\n"
     ]
    }
   ],
   "source": [
    "## use accuracy \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print (accuracy_score(y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = logistic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933333333333\n"
     ]
    }
   ],
   "source": [
    "print (accuracy_score(y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Another test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "X_train = X.reshape(len(X), 1)\n",
    "Y = np.array([1,1,1,-1,-1,-1,1,1,1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "tree.fit(X_train, Y)\n",
    "\n",
    "## prediction\n",
    "y_pred = tree.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "print (accuracy_score(y_pred, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write down the Adaboost algorithm based on this dataset step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Function that split the data set based on the x input**\n",
    "\n",
    "pseudo code:\n",
    "\n",
    "input: 1. array x\n",
    "       2. the number of threholds, N\n",
    "return: a list of threholds: res&nbsp;\n",
    "\n",
    "setup 1: res = []<br/>\n",
    "         min = x.min<br/>\n",
    "         max = x.max<br/>\n",
    "         pt = 0<br/>\n",
    "setup 2:<br/>\n",
    "         for i in range(N):<br/>\n",
    "             pt = pt + (max - min)/N<br/>\n",
    "             res.append(pt)<br/>\n",
    "return: res<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## implement the above function\n",
    "\n",
    "def threholds_list(x, n):\n",
    "    \"\"\"\n",
    "    x: input array.\n",
    "    n: integer, the number of splitting points\n",
    "    \n",
    "    return: a list of threholds point\n",
    "    \"\"\"\n",
    "    xmin = np.min(x)\n",
    "    xmax = np.max(x)\n",
    "    \n",
    "    pt = 0; res = []\n",
    "    for i in range(n):\n",
    "        pt = pt + np.floor(xmax - xmin - 1)/(n*1.0)\n",
    "        res.append(pt)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using weak classifier for training\n",
    "\n",
    "def norm(x, threhold, less_than = True):\n",
    "    if (less_than == True):\n",
    "        if x <= threhold:\n",
    "            return 1;\n",
    "        else:\n",
    "            return -1;\n",
    "    else:\n",
    "        if x > threhold:\n",
    "            return 1;\n",
    "        else:\n",
    "            return -1;\n",
    "\n",
    "def weakTrain(x, y, threhold, weight):\n",
    "    \"\"\"\n",
    "    input: x, training dataset\n",
    "           y, target value\n",
    "           threhold, the threhold from the list that used to\n",
    "           weight, an array represents the weight for each data\n",
    "    return: the error rate\n",
    "    \"\"\"\n",
    "    \n",
    "    error_less = 0;\n",
    "    error_more = 0;\n",
    "    \n",
    "    for ind in range(len(y)):\n",
    "        if (norm(x[ind,0], threhold, True) != y[ind]):\n",
    "            error_less = error_less + weight[ind]\n",
    "        if (norm(x[ind,0], threhold, False) != y[ind]):\n",
    "            error_more = error_more + weight[ind]\n",
    "    \n",
    "    if (error_less <= error_more):\n",
    "        return threhold, error_less, True\n",
    "    else:\n",
    "        return threhold, error_more, False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.4, True)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weakTrain(X_train, Y, 3, [1.0/10]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## alpha coefficient\n",
    "\n",
    "def get_alpha(error_rate):\n",
    "    \"\"\"\n",
    "    input: error_rate\n",
    "    output: the coefficient\n",
    "    \"\"\"\n",
    "    return 0.5*np.log((1-error_rate)/error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implement the algorithm\n",
    "\n",
    "def fit(x,y, num_iteration):\n",
    "    \"\"\"\n",
    "    This function will train the dataset. \n",
    "    input: x, training value\n",
    "           y, target value\n",
    "           num_iteration, integer, number of iterations\n",
    "    return:\n",
    "    \"\"\"\n",
    "    ## length of the data set\n",
    "    n = y.shape[0]\n",
    "    \n",
    "    ## Threholds list\n",
    "    threholds = threholds_list(x, n)\n",
    "    \n",
    "    ## initialize the the weight\n",
    "    weight = [1.0/n]*n\n",
    "    \n",
    "    ## collect all the weak classifier, and \n",
    "    weak_class = []\n",
    "    alphas = []\n",
    "    \n",
    "    for it in range(num_iteration):\n",
    "        \n",
    "        ## fake minimum, fake threhold\n",
    "        min_error = np.inf\n",
    "        min_threhold = 0\n",
    "        min_less = False\n",
    "        \n",
    "        for thre in threholds:\n",
    "            threhold, error, less = weakTrain(x, y, thre, weight)\n",
    "            \n",
    "            if (error <= min_error):\n",
    "                min_error = error\n",
    "                min_threhold = threhold\n",
    "                min_less = less\n",
    "        \n",
    "        ## save for latter use\n",
    "        weak_class.append((min_error, min_threhold, min_less))\n",
    "        \n",
    "        ## update weight:\n",
    "        alpha = get_alpha(min_error)\n",
    "        alphas.append(alpha)\n",
    "        \n",
    "        Zm = 0.0\n",
    "        for i in range(n):\n",
    "            Zm = Zm + weight[i]*np.exp(-alpha*y[i]*norm(x[i,0], min_threhold, min_less))\n",
    "            weight[i] = weight[i]*np.exp(-alpha*y[i]*norm(x[i,0], min_threhold, min_less))\n",
    "            \n",
    "        weight = weight/Zm\n",
    "        \n",
    "    return alphas, weak_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction\n",
    "\n",
    "def sign(x):\n",
    "    if (x >= 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def predict(x,alphas, weak_class):\n",
    "    \"\"\"\n",
    "    This function will make predictions\n",
    "    \"\"\"\n",
    "    y_pred = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        y_pred[i] = sign(np.sum(alphas[k]*norm(x[i], weak_class[k][1], weak_class[k][2]) for k in range(len(alphas))))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy after the adaptive boosting is: 0.900000\n"
     ]
    }
   ],
   "source": [
    "## make predictions on the X dataset\n",
    "\n",
    "alphas, weak_class = fit(X_train,Y, 3)\n",
    "\n",
    "y_pred = predict(X_train, alphas, weak_class)\n",
    "\n",
    "accuracy = np.sum(y_pred==Y)*1.0/Y.shape[0]\n",
    "\n",
    "print (\"The accuracy after the adaptive boosting is: %f\"%accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
